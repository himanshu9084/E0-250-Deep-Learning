{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proj3_logistic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfcBdzzvI5Ch",
        "colab_type": "code",
        "outputId": "922b449b-5323-4ae3-8c6f-91124863c1fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn import metrics   \n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "!pip install jsonlines\n",
        "\n",
        "\n",
        "import jsonlines\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "pst=PorterStemmer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Collecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.12.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC6xdPTYcnuo",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB7_IW70Jd39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_clean(text):\n",
        "  text=text.lower()\n",
        "  texty=word_tokenize(text)\n",
        "  texty=[word for word in texty if not word in stop_words]\n",
        "  for i in range(len(texty)):\n",
        "    texty[i]=pst.stem(texty[i])\n",
        "  sen = (\" \").join(texty)\n",
        "  sen=re.sub('[^a-zA-Z]',' ', sen)\n",
        "  sen = re.sub(r\"\\s+[a-zA-Z]\\s+\",' ', sen)\n",
        "  sen = re.sub(r'\\s+', ' ', sen)\n",
        "  #stop_tokens=[word for words in ]\n",
        "  return str(sen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NVpLf-NcquF",
        "colab_type": "code",
        "outputId": "e0816ff6-4f76-41b5-a24f-ba15afe35508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "chstr=text_clean('A dark-haired drummer is playing his set with enthusiasm.')\n",
        "print(chstr)\n",
        "print(word_tokenize(chstr))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dark hair drummer play set enthusiasm \n",
            "['dark', 'hair', 'drummer', 'play', 'set', 'enthusiasm']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLygMRJocw0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s1,s2,label=[],[],[]\n",
        "no_entry=[]\n",
        "Labels = ['contradiction','neutral','entailment','-']\n",
        "def data_read(): \n",
        "  s1.clear()\n",
        "  s2.clear()\n",
        "  label.clear()\n",
        "  no_entry.clear()\n",
        "  str_dev='/content/drive/My Drive/Colab Notebooks/Datasets/proj3/snli_1.0_dev.jsonl'\n",
        "  str_train='/content/drive/My Drive/Colab Notebooks/Datasets/proj3/snli_1.0_train.jsonl'\n",
        "  co=0\n",
        "  with jsonlines.open(str_train) as td:\n",
        "    for line in td.iter():\n",
        "      #print(line['sentence1']+'\\n',line['sentence2']+'\\n',line['gold_label'])\n",
        "      co=co+1\n",
        "      s1.append(text_clean(line['sentence1']))\n",
        "      s2.append(text_clean(line['sentence2']))   \n",
        "      if(line['gold_label']=='-'):\n",
        "        no_entry.append(co)\n",
        "      label.append(Labels.index(line['gold_label'].lower()))\n",
        "      #label.append(line['gold_label'].lower())\n",
        "data_read()\n",
        "label=np.array(label)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDFlFNDqkBbc",
        "colab_type": "code",
        "outputId": "20da793f-c44a-4f90-d58e-1f0602b4a5ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"{} sentences do not belong to any class\".format(len(no_entry)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "785 sentences do not belong to any class\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nr5k9bwD4Lz",
        "colab_type": "code",
        "outputId": "e515277e-caee-40e2-f606-8b9637013394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "xtext=[]\n",
        "for i in range(len(s1)):\n",
        "  fet=[]\n",
        "  s1i,s2i=word_tokenize(s1[i]),word_tokenize(s2[i])\n",
        "  for tokens in s1i:\n",
        "    fet.append(\"s1_\"+tokens)\n",
        "  for tokens in s2i:\n",
        "    fet.append(\"s2_\"+tokens)\n",
        "  xtext.append(\" \".join(fet))\n",
        "print(len(xtext))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "550152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx0z-LfFOzGE",
        "colab_type": "code",
        "outputId": "361d818d-e3a7-4ac4-b06e-a664aa2dacaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(xtext[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s1_person s1_hors s1_jump s1_broken s1_airplan s2_person s2_train s2_hors s2_competit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBzIYr-Rip5q",
        "colab_type": "text"
      },
      "source": [
        "TF-IDF usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RN2Txpi6vtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_vec=TfidfVectorizer(use_idf=True)\n",
        "full_fit=tfidf_vec.fit(xtext)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL1_xmjb9c_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feat1=full_fit.transform(xtext)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KUh2fsAw-NF",
        "colab_type": "code",
        "outputId": "dcd564ab-f701-47a4-cbe0-4590ab648927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pickle.dump(full_fit, open(\"tfidf.pickle\", \"wb\"))\n",
        "feat1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(550152, 31370)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QxRTN6iECL0",
        "colab_type": "text"
      },
      "source": [
        "Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjB_EeqJtone",
        "colab_type": "code",
        "outputId": "9cb1ad5e-a0d1-41aa-901c-1b8219a8ddd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "model = LogisticRegression(verbose=1, solver='newton-cg',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
        "model.fit(feat1, label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='newton-cg', tol=0.0001, verbose=1,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMmVy8y9so9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'logistic.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUd2pXPvRFKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model.predict(feat1)\n",
        "print(\"Train accuracy : {}\".format(model.score(feat1,label)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27NG3CMbpsAu",
        "colab_type": "code",
        "outputId": "f0f60ed5-dc9c-4de0-8dc8-55f8d80592b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "confusion_matrix = confusion_matrix(label, preds)\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[115406  29651  38130      0]\n",
            " [ 31994 112692  38078      0]\n",
            " [ 26402  23628 133386      0]\n",
            " [   197    261    327      0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SItvajpGSCF2",
        "colab_type": "code",
        "outputId": "13a69803-b1ab-41d7-f8ff-db63b8a2ed82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "print(classification_report(label, preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.63      0.65    183187\n",
            "           1       0.68      0.62      0.65    182764\n",
            "           2       0.64      0.73      0.68    183416\n",
            "           3       0.00      0.00      0.00       785\n",
            "\n",
            "    accuracy                           0.66    550152\n",
            "   macro avg       0.49      0.49      0.49    550152\n",
            "weighted avg       0.66      0.66      0.66    550152\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG9YnPmPszEw",
        "colab_type": "text"
      },
      "source": [
        "Loading saved model and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR5q5OLrs9Xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename='logistic.sav'\n",
        "sav_model=pickle.load(open(filename,'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k4cNo7Dt_G2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Labels = ['contradiction','neutral','entailment','-']\n",
        "str_test='/content/drive/My Drive/Colab Notebooks/Datasets/proj3/snli_1.0_test.jsonl'\n",
        "s1_test,s2_test,label_test=[],[],[]\n",
        "with jsonlines.open(str_test) as td:\n",
        "    for line in td.iter():\n",
        "      #print(line['sentence1']+'\\n',line['sentence2']+'\\n',line['gold_label'])\n",
        "      s1_test.append(text_clean(line['sentence1']))\n",
        "      s2_test.append(text_clean(line['sentence2']))\n",
        "      label_test.append(Labels.index(line['gold_label'].lower()))\n",
        "      #label.append(line['gold_label'].lower())\n",
        "label_test=np.array(label_test)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFH7yuS2u9p3",
        "colab_type": "code",
        "outputId": "5b877964-37e7-473a-fbb4-ea5c3c63c190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "xtext_test=[]\n",
        "for i in range(len(s1_test)):\n",
        "  fet=[]\n",
        "  s1i,s2i=word_tokenize(s1_test[i]),word_tokenize(s2_test[i])\n",
        "  for tokens in s1i:\n",
        "    fet.append(\"s1_\"+tokens)\n",
        "  for tokens in s2i:\n",
        "    fet.append(\"s2_\"+tokens)\n",
        "  xtext_test.append(\" \".join(fet))\n",
        "print(len(xtext_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DhMoNedvSsY",
        "colab_type": "code",
        "outputId": "fb6c622b-bcba-4a27-c8c0-ace82e750f6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tfidf_mod=pickle.load(open('tfidf.pickle','rb'))\n",
        "feat_test=tfidf_mod.transform(xtext_test)\n",
        "print((feat_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 31370)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN6T3ESgvqbz",
        "colab_type": "code",
        "outputId": "3ba771da-69c1-41ac-fcc3-bda780fe970c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_test = sav_model.predict(feat_test)\n",
        "print(\"Test accuracy : {}\".format(sav_model.score(feat_test,label_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy : 0.6317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U2B4dbgsziB",
        "colab_type": "code",
        "outputId": "1c0cf298-68ba-47fd-ed7d-fa559aa58c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(pred_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__yggJ6gs3dX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fp=open(\"tfidf.txt\",\"w\")\n",
        "for out in pred_test:\n",
        "  fp.write(Labels[out]+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP0cMvWo_tEs",
        "colab_type": "code",
        "outputId": "3568893d-0cb0-4581-93ea-a3738172dfc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "print(classification_report(label_test, pred_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.60      0.61      3237\n",
            "           1       0.65      0.61      0.63      3219\n",
            "           2       0.62      0.72      0.67      3368\n",
            "           3       0.00      0.00      0.00       176\n",
            "\n",
            "    accuracy                           0.63     10000\n",
            "   macro avg       0.47      0.48      0.48     10000\n",
            "weighted avg       0.62      0.63      0.63     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}